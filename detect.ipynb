{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['recognizer/handler/yolov5/models/best.pt'], source=recognizer/file_storage/17.jpg, data=recognizer/handler/yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=recognizer/handler/yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ 2022-6-13 Python-3.10.0 torch-1.11.0+cu102 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 444 layers, 86173414 parameters, 0 gradients\n",
      "image 1/1 /home/zorkin/Yandex.Disk/ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ/Hackathon/code/worker/recognizer/file_storage/17.jpg: 384x640 73 0s, Done. (0.449s)\n",
      "Speed: 0.5ms pre-process, 449.4ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mrecognizer/handler/yolov5/runs/detect/exp3\u001b[0m\n",
      "1 labels saved to recognizer/handler/yolov5/runs/detect/exp3/labels\n"
     ]
    }
   ],
   "source": [
    "!python recognizer/handler/yolov5/detect.py --weights recognizer/handler/yolov5/models/best.pt --source recognizer/file_storage/17.jpg --save-txt --save-conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks\n",
    "\n",
    "display.Image(filename='runs/detect/exp2/43.jpg', width=1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import utils\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "display = utils.notebook_init()  # checks\n",
    "labels = Path('runs/detect/exp5/labels/86.txt')\n",
    "image_path = 'data/images/86.jpg'\n",
    "new_image = 'data/images/86_1.jpg'\n",
    "\n",
    "with open(labels, 'r') as label:\n",
    "    coord = label.readlines()\n",
    "\n",
    "boxes = []    \n",
    "for box in coord:\n",
    "    box = box.replace('\\n','')\n",
    "    box = box.split()\n",
    "    boxes.append(box)\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "height, width, _ = image.shape\n",
    "\n",
    "print(height, width)\n",
    "for box in boxes:\n",
    "    x = int(float(box[1]) * width)\n",
    "    y = int(float(box[2]) * height)\n",
    "    #print(box)\n",
    "    #print(x, y)\n",
    "    cv2.circle(image, (x, y), 3, (0, 255, 0), 5)\n",
    "    \n",
    "msg = f'Warlus number = {len(boxes)}'\n",
    "\n",
    "cv2.putText(image, msg, (50, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 10, cv2.LINE_AA)\n",
    "  \n",
    "cv2.imwrite(new_image, image)\n",
    "\n",
    "#display.Image(filename=image_path)\n",
    "display.Image(filename=new_image)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e13c0b6539058f3aa8b1af83bc5e5a4bbf375e1eb54dba67290248d2d5f2675"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
